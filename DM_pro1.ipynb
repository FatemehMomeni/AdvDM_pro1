{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DM_pro1.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "LYIPhWRF4yy6",
        "U3cm87V5smzx",
        "3jvDmcu1d-aX",
        "05hX01ee2agD",
        "QbYhRxyq5BI1",
        "aHONfmBNX7AE",
        "DldWSpmDCOg2"
      ],
      "toc_visible": true,
      "mount_file_id": "1qeaDX_xPyoAWqYv2SzW_tgrNbk3y-u02",
      "authorship_tag": "ABX9TyMXHfY3Itf/QLUhMKmaw2vP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FatemehMomeni/AdvDM_pro1/blob/main/DM_pro1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries"
      ],
      "metadata": {
        "id": "LYIPhWRF4yy6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-V07eEkj74N"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Showing dataframe completely"
      ],
      "metadata": {
        "id": "U3cm87V5smzx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.width', 2000)\n",
        "pd.set_option('display.max_columns', 61)\n",
        "pd.set_option('display.max_rows', 200)"
      ],
      "metadata": {
        "id": "yIMYO1oNo20v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "8697234c-92cb-46c4-e89f-4f80f798f12a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-a4d6bd569cd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'display.width'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'display.max_columns'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m61\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'display.max_rows'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reading csv files"
      ],
      "metadata": {
        "id": "3jvDmcu1d-aX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "questions = pd.read_csv('/content/DM1_dataset/Questions.csv')\n",
        "answers = pd.read_csv('/content/DM1_dataset/Answers.csv')"
      ],
      "metadata": {
        "id": "9pGEHjkUeDJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Missing values"
      ],
      "metadata": {
        "id": "05hX01ee2agD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## calculating percentage"
      ],
      "metadata": {
        "id": "QbYhRxyq5BI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#counting number of missing values per column\n",
        "NaN_num = answers.isna().sum()\n",
        "\n",
        "#define a dictionary for storing percentage of missing values in each column\n",
        "NaN_percent = dict()\n",
        "answers_columns = answers.columns\n",
        "total_num = len(answers)\n",
        "\n",
        "#calculating percentage of missing values per column\n",
        "for num in range(len(NaN_num)):\n",
        "    NaN_percent[answers_columns[num]] = NaN_num[num] * 100 / total_num"
      ],
      "metadata": {
        "id": "74tafhKi2dHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Handling"
      ],
      "metadata": {
        "id": "HpQPVId45KUn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#sorting list of percentages to find columns with max number of missing values that stored in max_miss list\n",
        "sort = sorted(NaN_percent.items(), key=lambda x: x[1], reverse=True)\n",
        "max_miss = list()\n",
        "for i in sort:\n",
        "    if i[1] >= 70.0:\n",
        "        max_miss.append(i[0])\n",
        "    else:\n",
        "        break"
      ],
      "metadata": {
        "id": "wjTa2cBf5RLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# deleting columns have many missing values\n",
        "processed_ans = answers.drop(axis=1, columns=max_miss)"
      ],
      "metadata": {
        "id": "rUmADKmE5Z3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# finding type of columns\n",
        "print(processed_ans.dtypes)\n",
        "\n",
        "# filling missing values with mean for numeric(float64) columns\n",
        "numeric = ['Age', 'CompTotal', 'ConvertedComp', 'WorkWeekHrs']\n",
        "for i in numeric:\n",
        "    processed_ans[i] = processed_ans[i].fillna(processed_ans[i].mean())\n",
        "\n",
        "# filling missing values with mode for categorical columns\n",
        "categorical = ['MainBranch', 'Hobbyist', 'Age1stCode', 'CompFreq', 'Country', 'CurrencyDesc', 'CurrencySymbol',\n",
        "               'EdLevel', 'Employment', 'Ethnicity', 'Gender', 'JobSat', 'JobSeek', 'NEWDevOps', 'NEWDevOpsImpt',\n",
        "               'NEWEdImpt', 'NEWLearn', 'NEWOffTopic', 'NEWOnboardGood', 'NEWOtherComms', 'NEWOvertime',\n",
        "               'NEWPurchaseResearch', 'NEWPurpleLink', 'OpSys', 'OrgSize', 'PurchaseWhat', 'Sexuality', 'SOAccount',\n",
        "               'SOComm', 'SOPartFreq', 'SOVisitFreq', 'SurveyEase', 'SurveyLength', 'Trans', 'UndergradMajor',\n",
        "               'WelcomeChange', 'YearsCode', 'YearsCodePro']\n",
        "for i in categorical:\n",
        "    processed_ans[i] = processed_ans[i].fillna(processed_ans[i].mode()[0])"
      ],
      "metadata": {
        "id": "yyM7Qb1c5auS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remained columns\n",
        "remained = list()\n",
        "for i in answers_columns:\n",
        "    if i not in (max_miss + numeric + categorical):\n",
        "        remained.append(i)\n",
        "\n",
        "multi_value = dict()\n",
        "for i in range(1, len(remained)):\n",
        "    multi_value.clear()\n",
        "    column = processed_ans[remained[i]]\n",
        "    for row in column:\n",
        "        values = str(row).split(';')\n",
        "        for val in values:\n",
        "            if val != 'nan':\n",
        "                if val not in multi_value.keys():\n",
        "                    multi_value[val] = 1\n",
        "                else:\n",
        "                    multi_value[val] += 1\n",
        "    fill_value = max(multi_value, key=multi_value.get)\n",
        "    processed_ans[remained[i]] = processed_ans[remained[i]].fillna(fill_value)"
      ],
      "metadata": {
        "id": "5vCFNyOZ81yx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Outliers"
      ],
      "metadata": {
        "id": "dTrwj38-Blvd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# use label encoder to encode object data types\n",
        "encod_ans = processed_ans.copy()\n",
        "object_type = categorical + remained\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "for i in object_type:\n",
        "    encod_ans[i] = label_encoder.fit_transform(encod_ans[i])"
      ],
      "metadata": {
        "id": "WJZH7cXhBqqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show boxplot of all columns\n",
        "for i in encod_ans.columns:\n",
        "    plt.boxplot(encod_ans[i])\n",
        "    plt.title(i)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "dCq6Lfp4B0rZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# features without outlier\n",
        "no_outlier_columns = ['Respondent', 'CompFreq', 'Country', 'CurrencyDesc', 'CurrencySymbol', 'JobFactors',\n",
        "                      'JobSat', 'JobSeek', 'LanguageDesireNextYear', 'LanguageWorkedWith', 'MiscTechWorkedWith',\n",
        "                      'NEWCollabToolsWorkedWith', 'NEWDevOps', 'NEWEdImpt', 'NEWJobHuntResearch', 'NEWLearn',\n",
        "                      'NEWOffTopic', 'NEWOnboardGood', 'NEWOtherComms', 'NEWOvertime', 'NEWPurchaseResearch',\n",
        "                      'NEWPurpleLink', 'NEWStuck', 'OrgSize', 'PlatformDesireNextYear', 'PlatformWorkedWith', 'SOComm',\n",
        "                      'SOVisitFreq', 'SurveyEase', 'YearsCode', 'YearsCodePro']\n",
        "\n",
        "# discrete columns (no outlier)\n",
        "discrete_columns = ['Hobbyist', 'CompTotal', 'Gender', 'PurchaseWhat', 'Sexuality', 'SOAccount', 'SurveyLength', 'Trans',\n",
        "                    'UndergradMajor', 'WelcomeChange']"
      ],
      "metadata": {
        "id": "gXLV-WDoB8zv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# features with outlier\n",
        "outlier_columns = list()\n",
        "for i in encod_ans.columns:\n",
        "    if i not in (no_outlier_columns + discrete_columns):\n",
        "        outlier_columns.append(i)"
      ],
      "metadata": {
        "id": "0cd5z20TCMEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# columns which their outliers should be removed\n",
        "removes = ['MainBranch', 'EdLevel', 'Employment', 'NEWDevOpsImpt', 'OpSys', 'SOPartFreq']\n",
        "\n",
        "# outlier removal\n",
        "removable = list()\n",
        "for column in removes:\n",
        "    encod_ans_sort = encod_ans.sort_values(by=column, ascending=True)\n",
        "    q1 = np.quantile(encod_ans_sort[column], 0.25)\n",
        "    q3 = np.quantile(encod_ans_sort[column], 0.75)\n",
        "    IQR = q3 - q1\n",
        "    lower_fence = q1 - (1.5 * IQR)\n",
        "    upper_fence = q3 + (1.5 * IQR)\n",
        "    removable.clear()\n",
        "    for row in range(len(encod_ans)):\n",
        "        if encod_ans.loc[row, column] < lower_fence or encod_ans.loc[row, column] > upper_fence:\n",
        "            removable.append(row)\n",
        "    encod_ans.drop(removable, inplace=True)\n",
        "    encod_ans = encod_ans.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "ir9_It4HCQDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# imputing outlier with median\n",
        "outliers = list()\n",
        "for column in outlier_columns:\n",
        "    encod_ans_sort = encod_ans.sort_values(by=column, ascending=True)\n",
        "    q1 = np.quantile(encod_ans_sort[column], 0.25)\n",
        "    q3 = np.quantile(encod_ans_sort[column], 0.75)\n",
        "    IQR = q3 - q1\n",
        "    lower_fence = q1 - (1.5 * IQR)\n",
        "    upper_fence = q3 + (1.5 * IQR)\n",
        "    outliers.clear()\n",
        "    for row in range(len(encod_ans[column])):\n",
        "        if encod_ans.loc[row, column] < lower_fence or encod_ans.loc[row, column] > upper_fence:\n",
        "            outliers.append(row)\n",
        "    median = np.median(encod_ans[column])\n",
        "    for out in outliers:\n",
        "        encod_ans.loc[out, column] = median\n"
      ],
      "metadata": {
        "id": "eodXTS6d6qAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dependency"
      ],
      "metadata": {
        "id": "aHONfmBNX7AE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# columns dependency\n",
        "sns.scatterplot(x=\"MainBranch\", y=\"Age\", data=encod_ans)\n",
        "plt.show()\n",
        "sns.scatterplot(x=\"Age\", y=\"EdLevel\", data=encod_ans)\n",
        "plt.show()\n",
        "sns.scatterplot(x=\"Age1stCode\", y=\"YearsCode\", data=encod_ans)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Trx7AohCX_de"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Distribution"
      ],
      "metadata": {
        "id": "DldWSpmDCOg2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# distribution\n",
        "sns.displot(encod_ans['Age'])\n",
        "plt.show()\n",
        "sns.kdeplot(encod_ans['Age'])\n",
        "plt.show()\n",
        "sns.displot(encod_ans['EdLevel'])\n",
        "plt.show()\n",
        "sns.kdeplot(encod_ans['EdLevel'])\n",
        "plt.show()\n",
        "sns.displot(encod_ans['Gender'])\n",
        "plt.show()\n",
        "sns.kdeplot(encod_ans['Gender'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3X6dwn8IYH0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dimensionality reduction using PCA"
      ],
      "metadata": {
        "id": "CQBbNv_DSszp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(encod_ans.isnull().values.any())\n",
        "print(np.all(np.isfinite(encod_ans)))\n",
        "encod_ans = pd.DataFrame(np.nan_to_num(encod_ans), columns=answers_columns)"
      ],
      "metadata": {
        "id": "xJ4Zu8ivPyzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PCA\n",
        "pca_features = ['MainBranch', 'Hobbyist', 'Age', 'Age1stCode', 'CompFreq', 'CompTotal', 'ConvertedComp', 'Country']\n",
        "other_features = list()\n",
        "for i in encod_ans.columns:\n",
        "    if i not in pca_features:\n",
        "        other_features.append(i)\n",
        "\n",
        "pca_ans = encod_ans.loc[:, pca_features].values\n",
        "pca_ans = StandardScaler().fit_transform(pca_ans)\n",
        "pca = PCA(n_components=2)\n",
        "pc = pca.fit_transform(pd.DataFrame(np.nan_to_num(pca_ans), columns=pca_features))\n",
        "pc_df = pd.DataFrame(data=pc, columns=['principal component 1', 'principal component 2'])\n",
        "final_ans = pd.concat([pc_df, encod_ans[other_features]], axis=1)"
      ],
      "metadata": {
        "id": "m8t9s3aUSzB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Language Worked With"
      ],
      "metadata": {
        "id": "Pbc0V9_l8LAx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LanguageWorkedWith\n",
        "languages = list()\n",
        "for row in processed_ans['LanguageWorkedWith']:\n",
        "    values = str(row).split(';')\n",
        "    for v in values:\n",
        "        if v not in languages:\n",
        "            languages.append(v)\n",
        "\n",
        "lww_df = pd.DataFrame(0, index=np.arange(len(processed_ans)), columns=languages)\n",
        "for row in range(len(processed_ans)):\n",
        "    values = str(processed_ans.loc[row, 'LanguageWorkedWith']).split(';')\n",
        "    for e in values:\n",
        "        lww_df.loc[row, e] = 1\n",
        "    values.clear()"
      ],
      "metadata": {
        "id": "tplwax_H8Qhj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Questions"
      ],
      "metadata": {
        "id": "Te_qtEAQ-aag"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q1"
      ],
      "metadata": {
        "id": "AwVZk-G8-dIN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# most useful programming languages\n",
        "summation = dict()\n",
        "for i in lww_df.columns:\n",
        "    summation[i] = lww_df[i].sum()\n",
        "max_sum = max(summation.values())\n",
        "for i in summation:\n",
        "    if summation[i] == max_sum:\n",
        "        print(i)"
      ],
      "metadata": {
        "id": "tfgkZ8uY-e10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q2"
      ],
      "metadata": {
        "id": "eXbKdFFycw32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# countries with max salary\n",
        "df = encod_ans.copy()\n",
        "df['Avg'] = pd.DataFrame(df.groupby('Country')['CompTotal'].agg(Avg='mean')).reset_index()['Avg']\n",
        "print(max(df['Avg']))"
      ],
      "metadata": {
        "id": "0jI0EdfJc0S6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q3"
      ],
      "metadata": {
        "id": "ZWgsWZYtc2vs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# countries with max work hours\n",
        "df2 = encod_ans.copy()\n",
        "df2['Avg'] = pd.DataFrame(df.groupby('Country')['WorkWeekHrs'].agg(Avg='mean')).reset_index()['Avg']\n",
        "print(max(df2['Avg']))"
      ],
      "metadata": {
        "id": "vdEih7aRc4Gq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q4"
      ],
      "metadata": {
        "id": "aUzuGMucc4er"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# word cloud\n",
        "wordcloud = WordCloud(background_color=\"white\").generate(str(encod_ans['Country']))\n",
        "plt.figure(figsize=(20, 20))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NAeNbN18c5xt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}